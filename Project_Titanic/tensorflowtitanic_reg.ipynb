{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>MarriedName</th>\n",
       "      <th>FullName</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Level</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>Male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley</td>\n",
       "      <td>Florence Briggs Thayer</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath</td>\n",
       "      <td>Lily May Peel</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  PassengerId  Survived  Pclass                    MarriedName  \\\n",
       "0           0            1         0       3        Braund, Mr. Owen Harris   \n",
       "1           1            2         1       1    Cumings, Mrs. John Bradley    \n",
       "2           2            3         1       3         Heikkinen, Miss. Laina   \n",
       "3           3            4         1       1  Futrelle, Mrs. Jacques Heath    \n",
       "4           4            5         0       3       Allen, Mr. William Henry   \n",
       "\n",
       "                   FullName     Sex  Age  SibSp  Parch            Ticket  \\\n",
       "0   Braund, Mr. Owen Harris    Male   22      1      0         A/5 21171   \n",
       "1    Florence Briggs Thayer  Female   38      1      0          PC 17599   \n",
       "2    Heikkinen, Miss. Laina  Female   26      0      0  STON/O2. 3101282   \n",
       "3             Lily May Peel  Female   35      1      0            113803   \n",
       "4  Allen, Mr. William Henry    Male   35      0      0            373450   \n",
       "\n",
       "      Fare Cabin Level Embarked  \n",
       "0   7.2500     G     G        S  \n",
       "1  71.2833   C85     C        C  \n",
       "2   7.9250     G     G        S  \n",
       "3  53.1000  C123     C        S  \n",
       "4   8.0500     G     G        S  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "titanic=pd.read_csv(r'C:\\Users\\Russhi\\Desktop\\BOOTCAMP\\titanic_limpio.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_reg=titanic[['Pclass', 'Sex',\n",
    "       'Age', 'SibSp', 'Parch','Fare',\n",
    "       'Level','Embarked']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=titanic_reg['Fare'].copy()\n",
    "features=titanic_reg[['Pclass', 'Sex',\n",
    "       'Age', 'SibSp', 'Parch',\n",
    "       'Level','Embarked']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder= OneHotEncoder(drop='first', sparse_output=False)\n",
    "columnas=['Sex', 'Level', 'Embarked']\n",
    "categorical_data = features[columnas]\n",
    "encoded_categorical_data = pd.DataFrame(encoder.fit_transform(categorical_data))\n",
    "encoded_categorical_data.columns = encoder.get_feature_names_out(columnas)\n",
    "features = features.drop(['Sex', 'Level', 'Embarked'], axis=1)\n",
    "features = pd.concat([features, encoded_categorical_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Sex_Male</th>\n",
       "      <th>Level_B</th>\n",
       "      <th>Level_C</th>\n",
       "      <th>Level_D</th>\n",
       "      <th>Level_E</th>\n",
       "      <th>Level_F</th>\n",
       "      <th>Level_G</th>\n",
       "      <th>Level_T</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Age  SibSp  Parch  Sex_Male  Level_B  Level_C  Level_D  Level_E  \\\n",
       "0       3   22      1      0       1.0      0.0      0.0      0.0      0.0   \n",
       "1       1   38      1      0       0.0      0.0      1.0      0.0      0.0   \n",
       "2       3   26      0      0       0.0      0.0      0.0      0.0      0.0   \n",
       "3       1   35      1      0       0.0      0.0      1.0      0.0      0.0   \n",
       "4       3   35      0      0       1.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   Level_F  Level_G  Level_T  Embarked_Q  Embarked_S  \n",
       "0      0.0      1.0      0.0         0.0         1.0  \n",
       "1      0.0      0.0      0.0         0.0         0.0  \n",
       "2      0.0      1.0      0.0         0.0         1.0  \n",
       "3      0.0      0.0      0.0         0.0         1.0  \n",
       "4      0.0      1.0      0.0         0.0         1.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size= 0.2, random_state=357)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(X_train.shape[1],)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['mae','mse', tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 571.6100 - mae: 11.0827 - mse: 566.4006 - root_mean_squared_error: 23.7992\n",
      "Epoch 2/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 686.9769 - mae: 11.0048 - mse: 681.7657 - root_mean_squared_error: 26.1106\n",
      "Epoch 3/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 634.5660 - mae: 10.5927 - mse: 629.3554 - root_mean_squared_error: 25.0870\n",
      "Epoch 4/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 501.1646 - mae: 10.2739 - mse: 495.9459 - root_mean_squared_error: 22.2698\n",
      "Epoch 5/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 553.1516 - mae: 10.7365 - mse: 547.9257 - root_mean_squared_error: 23.4078\n",
      "Epoch 6/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 575.9266 - mae: 10.8999 - mse: 570.6985 - root_mean_squared_error: 23.8893\n",
      "Epoch 7/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 622.2328 - mae: 10.6877 - mse: 617.0032 - root_mean_squared_error: 24.8395\n",
      "Epoch 8/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 663.9280 - mae: 11.0236 - mse: 658.7040 - root_mean_squared_error: 25.6652\n",
      "Epoch 9/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 602.2907 - mae: 10.7744 - mse: 597.0593 - root_mean_squared_error: 24.4348\n",
      "Epoch 10/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 548.7569 - mae: 10.5636 - mse: 543.5218 - root_mean_squared_error: 23.3136\n",
      "Epoch 11/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 553.6866 - mae: 10.5151 - mse: 548.4467 - root_mean_squared_error: 23.4189\n",
      "Epoch 12/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 615.9576 - mae: 10.6292 - mse: 610.7024 - root_mean_squared_error: 24.7124\n",
      "Epoch 13/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 607.4316 - mae: 10.9031 - mse: 602.1628 - root_mean_squared_error: 24.5390\n",
      "Epoch 14/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 619.2061 - mae: 10.8243 - mse: 613.9343 - root_mean_squared_error: 24.7777\n",
      "Epoch 15/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 630.9550 - mae: 10.5930 - mse: 625.6873 - root_mean_squared_error: 25.0137\n",
      "Epoch 16/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 565.9196 - mae: 10.5600 - mse: 560.6464 - root_mean_squared_error: 23.6780\n",
      "Epoch 17/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 612.8575 - mae: 11.0080 - mse: 607.5650 - root_mean_squared_error: 24.6488\n",
      "Epoch 18/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 586.5974 - mae: 11.5222 - mse: 581.2856 - root_mean_squared_error: 24.1099\n",
      "Epoch 19/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 630.0553 - mae: 11.6539 - mse: 624.7394 - root_mean_squared_error: 24.9948\n",
      "Epoch 20/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 586.6684 - mae: 10.9174 - mse: 581.3647 - root_mean_squared_error: 24.1115\n",
      "Epoch 21/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 654.6290 - mae: 11.2731 - mse: 649.3347 - root_mean_squared_error: 25.4820\n",
      "Epoch 22/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 583.4421 - mae: 10.7353 - mse: 578.1489 - root_mean_squared_error: 24.0447\n",
      "Epoch 23/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 600.5648 - mae: 10.6809 - mse: 595.2811 - root_mean_squared_error: 24.3984\n",
      "Epoch 24/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 629.4918 - mae: 10.7548 - mse: 624.2124 - root_mean_squared_error: 24.9842\n",
      "Epoch 25/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 615.8762 - mae: 10.6893 - mse: 610.5913 - root_mean_squared_error: 24.7101\n",
      "Epoch 26/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 587.7646 - mae: 10.8963 - mse: 582.4623 - root_mean_squared_error: 24.1343\n",
      "Epoch 27/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 638.3999 - mae: 10.5586 - mse: 633.0936 - root_mean_squared_error: 25.1614\n",
      "Epoch 28/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 641.2430 - mae: 10.8161 - mse: 635.9344 - root_mean_squared_error: 25.2177\n",
      "Epoch 29/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 615.1442 - mae: 10.6378 - mse: 609.8414 - root_mean_squared_error: 24.6950\n",
      "Epoch 30/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 634.3886 - mae: 11.2462 - mse: 629.0862 - root_mean_squared_error: 25.0816\n",
      "Epoch 31/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 551.3029 - mae: 10.8763 - mse: 545.9910 - root_mean_squared_error: 23.3664\n",
      "Epoch 32/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 586.9855 - mae: 10.6059 - mse: 581.6648 - root_mean_squared_error: 24.1177\n",
      "Epoch 33/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 609.9604 - mae: 11.4416 - mse: 604.6299 - root_mean_squared_error: 24.5892\n",
      "Epoch 34/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 613.4756 - mae: 10.8311 - mse: 608.1360 - root_mean_squared_error: 24.6604\n",
      "Epoch 35/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 619.6793 - mae: 10.8937 - mse: 614.3349 - root_mean_squared_error: 24.7858\n",
      "Epoch 36/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 623.5074 - mae: 10.9045 - mse: 618.1752 - root_mean_squared_error: 24.8631\n",
      "Epoch 37/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 654.3885 - mae: 10.7539 - mse: 649.0706 - root_mean_squared_error: 25.4769\n",
      "Epoch 38/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 557.8552 - mae: 10.4526 - mse: 552.5303 - root_mean_squared_error: 23.5060\n",
      "Epoch 39/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 566.3178 - mae: 10.5058 - mse: 560.9752 - root_mean_squared_error: 23.6849\n",
      "Epoch 40/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 569.8931 - mae: 10.8424 - mse: 564.5334 - root_mean_squared_error: 23.7599\n",
      "Epoch 41/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 618.0555 - mae: 11.1452 - mse: 612.6807 - root_mean_squared_error: 24.7524\n",
      "Epoch 42/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 549.1642 - mae: 11.0563 - mse: 543.7755 - root_mean_squared_error: 23.3190\n",
      "Epoch 43/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 541.6229 - mae: 11.0926 - mse: 536.2263 - root_mean_squared_error: 23.1566\n",
      "Epoch 44/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 511.9326 - mae: 10.3491 - mse: 506.5328 - root_mean_squared_error: 22.5063\n",
      "Epoch 45/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 695.0184 - mae: 11.2221 - mse: 689.6194 - root_mean_squared_error: 26.2606\n",
      "Epoch 46/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 567.6935 - mae: 10.3945 - mse: 562.2894 - root_mean_squared_error: 23.7126\n",
      "Epoch 47/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 589.7220 - mae: 10.7522 - mse: 584.2966 - root_mean_squared_error: 24.1722\n",
      "Epoch 48/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 622.5197 - mae: 10.7439 - mse: 617.0867 - root_mean_squared_error: 24.8412\n",
      "Epoch 49/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 517.3488 - mae: 10.1100 - mse: 511.9161 - root_mean_squared_error: 22.6256\n",
      "Epoch 50/150\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 583.8678 - mae: 10.3439 - mse: 578.4371 - root_mean_squared_error: 24.0507\n",
      "Epoch 51/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 585.4104 - mae: 10.4445 - mse: 579.9773 - root_mean_squared_error: 24.0827\n",
      "Epoch 52/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 568.0807 - mae: 10.7034 - mse: 562.6373 - root_mean_squared_error: 23.7200\n",
      "Epoch 53/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 517.6370 - mae: 10.4871 - mse: 512.1866 - root_mean_squared_error: 22.6315\n",
      "Epoch 54/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 552.8583 - mae: 10.6791 - mse: 547.4034 - root_mean_squared_error: 23.3967\n",
      "Epoch 55/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 547.8145 - mae: 10.5525 - mse: 542.3500 - root_mean_squared_error: 23.2884\n",
      "Epoch 56/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 614.5373 - mae: 10.5525 - mse: 609.0598 - root_mean_squared_error: 24.6791\n",
      "Epoch 57/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 554.9956 - mae: 10.5432 - mse: 549.5159 - root_mean_squared_error: 23.4418\n",
      "Epoch 58/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 602.7312 - mae: 10.7304 - mse: 597.2419 - root_mean_squared_error: 24.4385\n",
      "Epoch 59/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 585.6618 - mae: 10.2251 - mse: 580.1710 - root_mean_squared_error: 24.0867\n",
      "Epoch 60/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 608.5242 - mae: 10.7051 - mse: 603.0333 - root_mean_squared_error: 24.5567\n",
      "Epoch 61/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 544.2222 - mae: 10.4652 - mse: 538.7408 - root_mean_squared_error: 23.2108\n",
      "Epoch 62/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 538.7057 - mae: 10.3456 - mse: 533.2204 - root_mean_squared_error: 23.0916\n",
      "Epoch 63/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 593.3241 - mae: 10.7143 - mse: 587.8237 - root_mean_squared_error: 24.2451\n",
      "Epoch 64/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 529.5801 - mae: 10.4612 - mse: 524.0773 - root_mean_squared_error: 22.8927\n",
      "Epoch 65/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 650.0945 - mae: 10.9255 - mse: 644.5793 - root_mean_squared_error: 25.3886\n",
      "Epoch 66/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 590.5654 - mae: 10.9015 - mse: 585.0411 - root_mean_squared_error: 24.1876\n",
      "Epoch 67/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 578.2426 - mae: 11.1076 - mse: 572.7210 - root_mean_squared_error: 23.9316\n",
      "Epoch 68/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 641.9908 - mae: 10.7401 - mse: 636.4765 - root_mean_squared_error: 25.2285\n",
      "Epoch 69/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 569.7277 - mae: 10.6883 - mse: 564.2159 - root_mean_squared_error: 23.7532\n",
      "Epoch 70/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 689.7255 - mae: 11.0429 - mse: 684.2057 - root_mean_squared_error: 26.1573\n",
      "Epoch 71/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 629.8214 - mae: 10.9484 - mse: 624.2976 - root_mean_squared_error: 24.9859\n",
      "Epoch 72/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 606.0424 - mae: 10.6473 - mse: 600.5136 - root_mean_squared_error: 24.5054\n",
      "Epoch 73/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 640.3370 - mae: 10.8958 - mse: 634.7947 - root_mean_squared_error: 25.1951\n",
      "Epoch 74/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 516.8339 - mae: 10.3059 - mse: 511.2956 - root_mean_squared_error: 22.6118\n",
      "Epoch 75/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 584.0479 - mae: 10.6237 - mse: 578.5116 - root_mean_squared_error: 24.0523\n",
      "Epoch 76/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 564.9495 - mae: 10.1373 - mse: 559.4172 - root_mean_squared_error: 23.6520\n",
      "Epoch 77/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 603.6669 - mae: 11.1252 - mse: 598.1367 - root_mean_squared_error: 24.4568\n",
      "Epoch 78/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 598.9598 - mae: 11.1385 - mse: 593.3877 - root_mean_squared_error: 24.3596\n",
      "Epoch 79/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 557.7419 - mae: 11.5657 - mse: 552.1252 - root_mean_squared_error: 23.4973\n",
      "Epoch 80/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 608.0130 - mae: 11.0393 - mse: 602.3931 - root_mean_squared_error: 24.5437\n",
      "Epoch 81/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 582.2244 - mae: 11.2202 - mse: 576.6049 - root_mean_squared_error: 24.0126\n",
      "Epoch 82/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 585.3166 - mae: 11.2677 - mse: 579.6921 - root_mean_squared_error: 24.0768\n",
      "Epoch 83/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 535.6208 - mae: 10.3249 - mse: 529.9951 - root_mean_squared_error: 23.0216\n",
      "Epoch 84/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 620.6727 - mae: 11.1730 - mse: 615.0418 - root_mean_squared_error: 24.8000\n",
      "Epoch 85/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 614.7790 - mae: 10.9037 - mse: 609.1432 - root_mean_squared_error: 24.6808\n",
      "Epoch 86/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 615.3184 - mae: 11.0426 - mse: 609.6719 - root_mean_squared_error: 24.6915\n",
      "Epoch 87/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 621.2409 - mae: 11.1226 - mse: 615.5902 - root_mean_squared_error: 24.8111\n",
      "Epoch 88/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 612.5163 - mae: 10.4034 - mse: 606.8652 - root_mean_squared_error: 24.6346\n",
      "Epoch 89/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 593.8328 - mae: 10.7655 - mse: 588.1798 - root_mean_squared_error: 24.2524\n",
      "Epoch 90/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 493.6471 - mae: 10.1366 - mse: 487.9924 - root_mean_squared_error: 22.0905\n",
      "Epoch 91/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 570.2061 - mae: 10.6315 - mse: 564.5510 - root_mean_squared_error: 23.7603\n",
      "Epoch 92/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 644.8168 - mae: 10.9018 - mse: 639.1510 - root_mean_squared_error: 25.2814\n",
      "Epoch 93/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 654.0291 - mae: 11.2501 - mse: 648.3548 - root_mean_squared_error: 25.4628\n",
      "Epoch 94/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 548.4717 - mae: 10.2208 - mse: 542.8019 - root_mean_squared_error: 23.2981\n",
      "Epoch 95/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 664.2933 - mae: 11.1110 - mse: 658.6277 - root_mean_squared_error: 25.6637\n",
      "Epoch 96/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 563.8296 - mae: 10.7091 - mse: 558.1686 - root_mean_squared_error: 23.6256\n",
      "Epoch 97/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 535.0558 - mae: 10.1716 - mse: 529.3852 - root_mean_squared_error: 23.0084\n",
      "Epoch 98/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 661.1371 - mae: 11.1365 - mse: 655.4564 - root_mean_squared_error: 25.6019\n",
      "Epoch 99/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 555.0688 - mae: 10.5848 - mse: 549.3776 - root_mean_squared_error: 23.4388\n",
      "Epoch 100/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 513.1100 - mae: 10.7064 - mse: 507.4163 - root_mean_squared_error: 22.5259\n",
      "Epoch 101/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 567.4391 - mae: 10.7644 - mse: 561.7194 - root_mean_squared_error: 23.7006\n",
      "Epoch 102/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 584.8055 - mae: 11.3847 - mse: 579.0598 - root_mean_squared_error: 24.0637\n",
      "Epoch 103/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 555.8558 - mae: 10.6124 - mse: 550.1060 - root_mean_squared_error: 23.4543\n",
      "Epoch 104/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 532.6054 - mae: 10.5022 - mse: 526.8584 - root_mean_squared_error: 22.9534\n",
      "Epoch 105/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 619.6560 - mae: 11.0109 - mse: 613.9160 - root_mean_squared_error: 24.7773\n",
      "Epoch 106/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 594.4771 - mae: 10.6793 - mse: 588.7346 - root_mean_squared_error: 24.2639\n",
      "Epoch 107/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 525.7074 - mae: 10.5725 - mse: 519.9665 - root_mean_squared_error: 22.8028\n",
      "Epoch 108/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 578.5303 - mae: 10.8067 - mse: 572.7828 - root_mean_squared_error: 23.9329\n",
      "Epoch 109/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 558.0886 - mae: 10.7845 - mse: 552.3264 - root_mean_squared_error: 23.5016\n",
      "Epoch 110/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 632.4250 - mae: 10.6828 - mse: 626.6496 - root_mean_squared_error: 25.0330\n",
      "Epoch 111/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 571.3629 - mae: 10.7584 - mse: 565.5759 - root_mean_squared_error: 23.7818\n",
      "Epoch 112/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 563.1425 - mae: 10.9367 - mse: 557.3540 - root_mean_squared_error: 23.6083\n",
      "Epoch 113/150\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 561.2336 - mae: 10.4862 - mse: 555.4338 - root_mean_squared_error: 23.5676\n",
      "Epoch 114/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 592.6943 - mae: 11.1440 - mse: 586.8750 - root_mean_squared_error: 24.2255\n",
      "Epoch 115/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 550.4524 - mae: 10.4002 - mse: 544.6330 - root_mean_squared_error: 23.3374\n",
      "Epoch 116/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 661.8478 - mae: 10.8142 - mse: 656.0291 - root_mean_squared_error: 25.6131\n",
      "Epoch 117/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 578.3995 - mae: 10.9243 - mse: 572.5773 - root_mean_squared_error: 23.9286\n",
      "Epoch 118/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 509.6392 - mae: 10.6505 - mse: 503.8146 - root_mean_squared_error: 22.4458\n",
      "Epoch 119/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 673.2131 - mae: 11.4368 - mse: 667.3873 - root_mean_squared_error: 25.8338\n",
      "Epoch 120/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 565.4118 - mae: 10.8577 - mse: 559.5884 - root_mean_squared_error: 23.6556\n",
      "Epoch 121/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 507.1113 - mae: 10.3276 - mse: 501.2759 - root_mean_squared_error: 22.3892\n",
      "Epoch 122/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 622.2675 - mae: 11.0047 - mse: 616.4201 - root_mean_squared_error: 24.8278\n",
      "Epoch 123/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 578.7570 - mae: 10.3800 - mse: 572.9116 - root_mean_squared_error: 23.9356\n",
      "Epoch 124/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 583.3959 - mae: 10.8050 - mse: 577.5418 - root_mean_squared_error: 24.0321\n",
      "Epoch 125/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 533.2936 - mae: 10.4112 - mse: 527.4302 - root_mean_squared_error: 22.9658\n",
      "Epoch 126/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 681.2614 - mae: 11.5250 - mse: 675.4019 - root_mean_squared_error: 25.9885\n",
      "Epoch 127/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 609.6099 - mae: 10.6498 - mse: 603.7467 - root_mean_squared_error: 24.5713\n",
      "Epoch 128/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 538.0896 - mae: 10.5202 - mse: 532.2158 - root_mean_squared_error: 23.0698\n",
      "Epoch 129/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 566.2017 - mae: 10.5252 - mse: 560.3154 - root_mean_squared_error: 23.6710\n",
      "Epoch 130/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 646.2770 - mae: 11.2796 - mse: 640.3901 - root_mean_squared_error: 25.3059\n",
      "Epoch 131/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 474.7266 - mae: 10.6032 - mse: 468.8199 - root_mean_squared_error: 21.6522\n",
      "Epoch 132/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 591.3726 - mae: 11.6972 - mse: 585.4423 - root_mean_squared_error: 24.1959\n",
      "Epoch 133/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 679.6998 - mae: 11.7761 - mse: 673.7788 - root_mean_squared_error: 25.9572\n",
      "Epoch 134/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 569.8827 - mae: 10.9575 - mse: 563.9740 - root_mean_squared_error: 23.7481\n",
      "Epoch 135/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 560.5935 - mae: 10.7696 - mse: 554.6822 - root_mean_squared_error: 23.5517\n",
      "Epoch 136/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 536.8057 - mae: 10.6195 - mse: 530.8865 - root_mean_squared_error: 23.0410\n",
      "Epoch 137/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 531.5992 - mae: 10.6443 - mse: 525.6841 - root_mean_squared_error: 22.9278\n",
      "Epoch 138/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 642.5649 - mae: 11.0752 - mse: 636.6605 - root_mean_squared_error: 25.2321\n",
      "Epoch 139/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 575.2124 - mae: 10.8729 - mse: 569.3063 - root_mean_squared_error: 23.8601\n",
      "Epoch 140/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 569.9342 - mae: 10.6009 - mse: 564.0118 - root_mean_squared_error: 23.7489\n",
      "Epoch 141/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 533.9197 - mae: 10.5519 - mse: 527.9775 - root_mean_squared_error: 22.9778\n",
      "Epoch 142/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 536.7721 - mae: 10.2018 - mse: 530.8182 - root_mean_squared_error: 23.0395\n",
      "Epoch 143/150\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 556.8827 - mae: 10.6088 - mse: 550.9210 - root_mean_squared_error: 23.4717\n",
      "Epoch 144/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 488.2697 - mae: 10.4948 - mse: 482.3041 - root_mean_squared_error: 21.9614\n",
      "Epoch 145/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 545.4258 - mae: 10.5918 - mse: 539.4609 - root_mean_squared_error: 23.2263\n",
      "Epoch 146/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 536.2159 - mae: 10.1132 - mse: 530.2521 - root_mean_squared_error: 23.0272\n",
      "Epoch 147/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 597.9016 - mae: 10.8836 - mse: 591.9343 - root_mean_squared_error: 24.3297\n",
      "Epoch 148/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 559.5016 - mae: 11.1065 - mse: 553.5263 - root_mean_squared_error: 23.5271\n",
      "Epoch 149/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 536.7335 - mae: 10.3129 - mse: 530.7466 - root_mean_squared_error: 23.0379\n",
      "Epoch 150/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 556.0310 - mae: 10.3526 - mse: 550.0285 - root_mean_squared_error: 23.4527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x230990990c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=150, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 798us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2439.567812790622\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Russhi\\Desktop\\BOOTCAMP\\venv_analytics\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('tensorflowtitanic.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'tensorflowtitanic.h5' at http://localhost:8080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 8080)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import netron\n",
    "\n",
    "netron.start(\"tensorflowtitanic.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implementación de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "Pclass = int(input(\"Clase del pasajero (1,2 o 3): \"))\n",
    "Sex = input(\"Male or Female: \")\n",
    "Age = int(input(\"Edad del pasajero: \"))\n",
    "SibSp = int(input(\"Número de hermanos + cónyuje a bordo: \"))\n",
    "Parch = int(input(\"Número de padres e hijos a bordo: \"))\n",
    "\n",
    "if Pclass == 1:\n",
    "    Level = input(\"Nivel del barco ('A', 'B', 'C', 'D', 'E')\")\n",
    "elif Pclass==2:\n",
    "    Level = input(\"Nivel del barco ('B', 'C', 'D', 'E','F')\")\n",
    "else:\n",
    "    Level = input(\"Nivel del barco ('D', 'E','F', 'G')\")\n",
    "\n",
    "Embarked = input(\"Puerto de embarque ('S', 'C' o 'Q'): \")\n",
    "\n",
    "\n",
    "def prediccion_fare(Pclass, Sex, Age, SibSp, Parch, Level, Embarked):\n",
    "    data = pd.DataFrame(columns=['Pclass', 'Age', 'SibSp', 'Parch', 'Sex_Male', 'Level_B',\n",
    "       'Level_C', 'Level_D', 'Level_E', 'Level_F', 'Level_G', 'Level_T',\n",
    "       'Embarked_Q', 'Embarked_S'])\n",
    "    \n",
    "    pclass_std=(Pclass-1)/(3-1)\n",
    "    data.loc[0,'Pclass']=(pclass_std*(1-0))+0\n",
    "    age_std=(Age-0)/(80-0)\n",
    "    data.loc[0,'Age']=(age_std*(1-0))+0\n",
    "    sibsp_std=(SibSp-0)/(8-0)\n",
    "    data.loc[0,'SibSp']=(sibsp_std*(1-0))+0\n",
    "    parch_std=(Parch-0)/(6-0)\n",
    "    data.loc[0,'Parch']=(parch_std*(1-0))+0\n",
    "\n",
    "    if Sex=='Male':\n",
    "        data.loc[0,'Sex_Male']=1\n",
    "    else:\n",
    "        data.loc[0,'Sex_Male']=0\n",
    "\n",
    "    if Embarked=='C':\n",
    "        data.loc[0,['Embarked_Q','Embarked_S']]=0\n",
    "    elif Embarked=='Q':\n",
    "        data.loc[0, ['Embarked_Q', 'Embarked_S']] = [1, 0]\n",
    "    else:\n",
    "        data.loc[0, ['Embarked_Q', 'Embarked_S']] = [0, 1]\n",
    "\n",
    "    if Level=='A':\n",
    "        data.loc[0,['Level_B',\n",
    "                    'Level_C', 'Level_D', 'Level_E', 'Level_F', 'Level_G', 'Level_T']]=[0,0,0,0,0,0,0]\n",
    "    elif Level=='B':\n",
    "        data.loc[0,['Level_B',\n",
    "                    'Level_C', 'Level_D', 'Level_E', 'Level_F', 'Level_G', 'Level_T']]=[1,0,0,0,0,0,0]\n",
    "    elif Level=='C':\n",
    "        data.loc[0,['Level_B',\n",
    "                    'Level_C', 'Level_D', 'Level_E', 'Level_F', 'Level_G', 'Level_T']]=[0,1,0,0,0,0,0]\n",
    "    elif Level=='D':\n",
    "        data.loc[0,['Level_B',\n",
    "                    'Level_C', 'Level_D', 'Level_E', 'Level_F', 'Level_G', 'Level_T']]=[0,0,1,0,0,0,0]\n",
    "    elif Level=='E':\n",
    "        data.loc[0,['Level_B',\n",
    "                    'Level_C', 'Level_D', 'Level_E', 'Level_F', 'Level_G', 'Level_T']]=[0,0,0,1,0,0,0]\n",
    "    elif Level=='F':\n",
    "        data.loc[0,['Level_B',\n",
    "                    'Level_C', 'Level_D', 'Level_E', 'Level_F', 'Level_G', 'Level_T']]=[0,0,0,0,1,0,0]\n",
    "    elif Level=='G':\n",
    "        data.loc[0,['Level_B',\n",
    "                    'Level_C', 'Level_D', 'Level_E', 'Level_F', 'Level_G', 'Level_T']]=[0,0,0,0,0,1,0]\n",
    "    else:\n",
    "        data.loc[0,['Level_B',\n",
    "                    'Level_C', 'Level_D', 'Level_E', 'Level_F', 'Level_G', 'Level_T']]=[0,0,0,0,0,0,1]\n",
    "                    \n",
    "    data = data.astype(float)\n",
    "    X=data.values\n",
    "    \n",
    "    modelo=load_model('tensorflowtitanic.h5')  \n",
    "    predictions = modelo.predict(X)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "prediction=prediccion_fare(Pclass, Sex, Age, SibSp, Parch, Level, Embarked)\n",
    "\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
